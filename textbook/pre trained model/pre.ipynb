{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "59DUGhvABOHo",
        "colab_type": "code",
        "outputId": "bc0468fc-c7f6-4071-983c-0112521d0405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G   23G  318G   7% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G   12K  6.4G   1% /var/colab\n",
            "/dev/sda1       365G   27G  339G   8% /opt/bin\n",
            "shm             6.0G     0  6.0G   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RuDXNcH4BSvD",
        "colab_type": "code",
        "outputId": "21be0811-2b7f-445c-9611-3c5e9312ede1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        535M         10G        900K        1.7G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yPuQkw39HA_w",
        "colab_type": "code",
        "outputId": "e647caa1-f800-4133-e765-8859734601d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install mxnet-cu100 gluoncv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/36/40b6d201b46495513f7a7fa25fe8b7d85b3602a22efba119e8146d5f1601/mxnet_cu100-1.4.0.post0-py2.py3-none-manylinux1_x86_64.whl (487.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 487.9MB 37kB/s \n",
            "\u001b[?25hCollecting gluoncv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/2b/73c2cfd4fc72101f9087bf1d2290286418a1428274d5c3d022146baed021/gluoncv-0.3.0-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Collecting requests>=2.20.0 (from mxnet-cu100)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gluoncv) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gluoncv) (4.28.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from gluoncv) (3.0.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.22)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->gluoncv) (0.46)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->gluoncv) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->gluoncv) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (40.8.0)\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.48 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, graphviz, mxnet-cu100, gluoncv\n",
            "  Found existing installation: requests 2.18.4\n",
            "    Uninstalling requests-2.18.4:\n",
            "      Successfully uninstalled requests-2.18.4\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed gluoncv-0.3.0 graphviz-0.8.4 mxnet-cu100-1.4.0.post0 requests-2.21.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyVMwPgJCUBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, random, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "\n",
        "from mxnet import gluon, nd\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, TrainingHistory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wyPwaMKffUq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sef3m6zZCiRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of GPUs to use\n",
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "\n",
        "# Get the model CIFAR_ResNet20_v1, with 10 output classes, without pre-trained weights\n",
        "net = get_model('cifar_resnet20_v1', classes=10, pretrained=False)\n",
        "# net.collect_params().reset_ctx(ctx)\n",
        "\n",
        "net.initialize(mx.init.Xavier(), ctx = ctx)\n",
        "# net.hybridize()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NK8t5vgtCsbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    # Randomly crop an area, and then resize it to be 32x32\n",
        "#     transforms.RandomResizedCrop(28),\n",
        "    # Randomly flip the image horizontally\n",
        "    transforms.RandomFlipLeftRight(),\n",
        "    # Randomly jitter the brightness, contrast and saturation of the image\n",
        "    transforms.RandomColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    # Randomly adding noise to the image\n",
        "    transforms.RandomLighting(0.1),\n",
        "    # Transpose the image from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    transforms.ToTensor(),\n",
        "    # Normalize the image with mean and standard deviation calculated across all images\n",
        "#     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
        "    # one channel\n",
        "    transforms.Normalize([0.4914], [0.2023])\n",
        "\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "32MlbdSDC6be",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_test = transforms.Compose([\n",
        "#     transforms.Resize(28),\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
        "    transforms.Normalize([0.4914], [0.2023])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kT4MRfipDRr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Batch Size for Each GPU\n",
        "per_device_batch_size = 64\n",
        "# Number of data loader workers\n",
        "num_workers = 8\n",
        "# Calculate effective total batch size\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "# Set train=True for training data\n",
        "# Set shuffle=True to shuffle the training data\n",
        "train_data = gluon.data.DataLoader(\n",
        "    gluon.data.vision.FashionMNIST(train=True).transform_first(transform_train),\n",
        "    batch_size=batch_size, shuffle=True, last_batch='discard', num_workers=num_workers)\n",
        "\n",
        "# Set train=False for validation data\n",
        "val_data = gluon.data.DataLoader(\n",
        "    gluon.data.vision.FashionMNIST(train=False).transform_first(transform_test),\n",
        "    batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2r_vuKADXEH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Learning rate decay factor\n",
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [80, 150, np.inf]\n",
        "\n",
        "# Nesterov accelerated gradient descent\n",
        "optimizer = 'nag'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.1, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Empt0i1DiXW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "# print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mngZVqeqESZf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-error', 'validation-error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jh1Reo4eEcab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(ctx, val_data):\n",
        "    metric = mx.metric.Accuracy()\n",
        "    for i, batch in enumerate(val_data):\n",
        "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "        outputs = [net(X) for X in data]\n",
        "        metric.update(label, outputs)\n",
        "    return metric.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTrfaXnzEeup",
        "colab_type": "code",
        "outputId": "62cf04cc-4065-4bc4-deca-be373345fcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "epochs=200\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = [net(X) for X in data]\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.sum().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "    # Evaluate on Validation data\n",
        "    name, val_acc = test(ctx, val_data)\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([1-acc, 1-val_acc])\n",
        "    print('[Epoch %d] train=%f val=%f loss=%f time: %f learning_rate: %f'  %\n",
        "        (epoch, acc, val_acc, train_loss, time.time()-tic ,trainer.learning_rate))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "\n",
        "train_history.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0] train=0.835762 val=0.870200 loss=27173.214324 time: 74.967051 learning_rate: 0.100000\n",
            "[Epoch 1] train=0.892910 val=0.896000 loss=17529.751056 time: 71.130558 learning_rate: 0.100000\n",
            "[Epoch 2] train=0.907217 val=0.910900 loss=15300.600327 time: 71.327368 learning_rate: 0.100000\n",
            "[Epoch 3] train=0.914805 val=0.915100 loss=14002.874303 time: 71.472617 learning_rate: 0.100000\n",
            "[Epoch 4] train=0.919574 val=0.921600 loss=13249.398613 time: 76.085972 learning_rate: 0.100000\n",
            "[Epoch 5] train=0.921525 val=0.921200 loss=12808.759727 time: 73.957966 learning_rate: 0.100000\n",
            "[Epoch 6] train=0.926261 val=0.920300 loss=12164.984082 time: 74.551862 learning_rate: 0.100000\n",
            "[Epoch 7] train=0.928862 val=0.926500 loss=11907.413461 time: 73.861351 learning_rate: 0.100000\n",
            "[Epoch 8] train=0.932030 val=0.925200 loss=11416.310748 time: 70.457989 learning_rate: 0.100000\n",
            "[Epoch 9] train=0.931547 val=0.920700 loss=11368.430602 time: 70.854014 learning_rate: 0.100000\n",
            "[Epoch 10] train=0.933198 val=0.913900 loss=11067.811541 time: 73.648000 learning_rate: 0.100000\n",
            "[Epoch 11] train=0.934398 val=0.922100 loss=10757.067139 time: 74.995048 learning_rate: 0.100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gCtAG3snHR4-",
        "colab_type": "code",
        "outputId": "5cb4b493-3da3-41f7-be11-115238731ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWgJEYI1FD_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.save_parameters('/content/gdrive/My Drive/dive_deep_cifar10_resnet110_v2.params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sC7Hd_wQFHBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net.load_parameters('/content/gdrive/My Drive/dive_deep_cifar10_resnet56_v1.params', ctx=ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MozNaHPW5mQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}