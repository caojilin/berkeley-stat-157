{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:28:00.562087Z",
     "start_time": "2019-03-08T06:28:00.551275Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '..')\n",
    "\n",
    "import d2l\n",
    "import math\n",
    "from mxnet import autograd, nd\n",
    "from mxnet.gluon import loss as gloss\n",
    "import time\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = \\\n",
    "    d2l.load_data_time_machine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:28:12.330690Z",
     "start_time": "2019-03-08T06:28:12.313807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       "<NDArray 2x43 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.one_hot(nd.array([0, 2]), vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:29:52.819431Z",
     "start_time": "2019-03-08T06:29:52.762474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, (2, 43))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function is saved in the d2l package for future use\n",
    "def to_onehot(X, size):\n",
    "    return [nd.one_hot(x, size) for x in X.T]\n",
    "\n",
    "X = nd.arange(10).reshape((2, 5))\n",
    "inputs = to_onehot(X, vocab_size)\n",
    "len(inputs), inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:32:45.016090Z",
     "start_time": "2019-03-08T06:32:45.006542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 1. 2. 3. 4.]\n",
       " [5. 6. 7. 8. 9.]]\n",
       "<NDArray 2x5 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:32:50.478124Z",
     "start_time": "2019-03-08T06:32:50.461711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       " <NDArray 2x43 @cpu(0)>, \n",
       " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       " <NDArray 2x43 @cpu(0)>, \n",
       " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       " <NDArray 2x43 @cpu(0)>, \n",
       " [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       " <NDArray 2x43 @cpu(0)>, \n",
       " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
       " <NDArray 2x43 @cpu(0)>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:34:47.537341Z",
     "start_time": "2019-03-08T06:34:47.515732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu(0)\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 512, vocab_size\n",
    "ctx = d2l.try_gpu()\n",
    "print('Using', ctx)\n",
    "\n",
    "# Create the parameters of the model, initialize them and attach gradients\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        return nd.random.normal(scale=0.01, shape=shape, ctx=ctx)\n",
    "\n",
    "    # Hidden layer parameters\n",
    "    W_xh = _one((num_inputs, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = nd.zeros(num_hiddens, ctx=ctx)\n",
    "    # Output layer parameters\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = nd.zeros(num_outputs, ctx=ctx)\n",
    "    # Attach a gradient\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:36:45.665708Z",
     "start_time": "2019-03-08T06:36:45.658957Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, ctx):\n",
    "    return (nd.zeros(shape=(batch_size, num_hiddens), ctx=ctx), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:37:57.752124Z",
     "start_time": "2019-03-08T06:37:57.743050Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # Both inputs and outputs are composed of num_steps matrices of the shape\n",
    "    # (batch_size, vocab_size)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = nd.tanh(nd.dot(X, W_xh) + nd.dot(H, W_hh) + b_h)\n",
    "        Y = nd.dot(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:39:39.633779Z",
     "start_time": "2019-03-08T06:39:39.619078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, (2, 43), (2, 512))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = init_rnn_state(X.shape[0], num_hiddens, ctx)\n",
    "inputs = to_onehot(X.as_in_context(ctx), vocab_size)\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "len(outputs), outputs[0].shape, state_new[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:52:29.646304Z",
     "start_time": "2019-03-08T06:52:29.633555Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function is saved in the d2l package for future use\n",
    "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    state = init_rnn_state(1, num_hiddens, ctx)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        # The output of the previous time step is taken as the input of the\n",
    "        # current time step.\n",
    "        X = to_onehot(nd.array([output[-1]], ctx=ctx), vocab_size)\n",
    "        # Calculate the output and update the hidden state\n",
    "        (Y, state) = rnn(X, state, params)\n",
    "        \n",
    "        # The input to the next time step is the character in the prefix or\n",
    "        # the current best predicted character\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            # This is maximum likelihood decoding, not sampling\n",
    "#             print(Y[0].argmax(axis=1).asscalar())\n",
    "            output.append(int(Y[0].argmax(axis=1).asscalar()))\n",
    "        \n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T06:52:30.352845Z",
     "start_time": "2019-03-08T06:52:30.318113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "35.0\n",
      "9.0\n",
      "0.0\n",
      "41.0\n",
      "37.0\n",
      "8.0\n",
      "42.0\n",
      "19.0\n",
      "19.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'j': 0,\n",
       " ')': 1,\n",
       " '1': 2,\n",
       " 'r': 3,\n",
       " \"'\": 4,\n",
       " 'p': 5,\n",
       " '.': 6,\n",
       " 'c': 7,\n",
       " 'm': 8,\n",
       " 'h': 9,\n",
       " 'x': 10,\n",
       " '?': 11,\n",
       " 't': 12,\n",
       " ']': 13,\n",
       " 'o': 14,\n",
       " 'd': 15,\n",
       " 'w': 16,\n",
       " 'q': 17,\n",
       " 'a': 18,\n",
       " ' ': 19,\n",
       " 'e': 20,\n",
       " '9': 21,\n",
       " 'y': 22,\n",
       " ';': 23,\n",
       " 'f': 24,\n",
       " '_': 25,\n",
       " ':': 26,\n",
       " 'n': 27,\n",
       " '-': 28,\n",
       " 'k': 29,\n",
       " 's': 30,\n",
       " 'v': 31,\n",
       " '!': 32,\n",
       " '[': 33,\n",
       " 'z': 34,\n",
       " '8': 35,\n",
       " '(': 36,\n",
       " 'i': 37,\n",
       " 'g': 38,\n",
       " ',': 39,\n",
       " 'b': 40,\n",
       " 'u': 41,\n",
       " 'l': 42}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn('traveller', 10, rnn, params, init_rnn_state, num_hiddens,\n",
    "            vocab_size, ctx, idx_to_char, char_to_idx)\n",
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
