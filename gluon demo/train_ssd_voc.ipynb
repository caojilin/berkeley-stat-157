{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "04. Train SSD on Pascal VOC dataset\n======================================\n\nThis tutorial goes through the basic building blocks of object detection\nprovided by GluonCV.\nSpecifically, we show how to build a state-of-the-art Single Shot Multibox\nDetection [Liu16]_ model by stacking GluonCV components.\nThis is also a good starting point for your own object detection project.\n\n.. hint::\n\n    You can skip the rest of this tutorial and start training your SSD model\n    right away by downloading this script:\n\n    :download:`Download train_ssd.py<../../../scripts/detection/ssd/train_ssd.py>`\n\n    Example usage:\n\n    Train a default vgg16_atrous 300x300 model with Pascal VOC on GPU 0:\n\n    .. code-block:: bash\n\n        python train_ssd.py\n\n    Train a resnet50_v1 512x512 model on GPU 0,1,2,3:\n\n    .. code-block:: bash\n\n        python train_ssd.py --gpus 0,1,2,3 --network resnet50_v1 --data-shape 512\n\n    Check the supported arguments:\n\n    .. code-block:: bash\n\n        python train_ssd.py --help\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset\n-------\n\nPlease first go through this `sphx_glr_build_examples_datasets_pascal_voc.py` tutorial to setup Pascal\nVOC dataset on your disk.\nThen, we are ready to load training and validation images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv.data import VOCDetection\n# typically we use 2007+2012 trainval splits for training data\ntrain_dataset = VOCDetection(splits=[(2007, 'trainval'), (2012, 'trainval')])\n# and use 2007 test as validation data\nval_dataset = VOCDetection(splits=[(2007, 'test')])\n\nprint('Training images:', len(train_dataset))\nprint('Validation images:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data transform\n------------------\nWe can read an image-label pair from the training dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_image, train_label = train_dataset[0]\nbboxes = train_label[:, :4]\ncids = train_label[:, 4:5]\nprint('image:', train_image.shape)\nprint('bboxes:', bboxes.shape, 'class ids:', cids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the image, together with the bounding box labels:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nfrom gluoncv.utils import viz\n\nax = viz.plot_bbox(\n    train_image.asnumpy(),\n    bboxes,\n    labels=cids,\n    class_names=train_dataset.classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation images are quite similar to training because they were\nbasically split randomly to different sets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "val_image, val_label = val_dataset[0]\nbboxes = val_label[:, :4]\ncids = val_label[:, 4:5]\nax = viz.plot_bbox(\n    val_image.asnumpy(),\n    bboxes,\n    labels=cids,\n    class_names=train_dataset.classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For SSD networks, it is critical to apply data augmentation (see explanations in paper [Liu16]_).\nWe provide tons of image and bounding box transform functions to do that.\nThey are very convenient to use as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv.data.transforms import presets\nfrom gluoncv import utils\nfrom mxnet import nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "width, height = 512, 512  # suppose we use 512 as base training size\ntrain_transform = presets.ssd.SSDDefaultTrainTransform(width, height)\nval_transform = presets.ssd.SSDDefaultValTransform(width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "utils.random.seed(233)  # fix seed in this tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "apply transforms to train image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_image2, train_label2 = train_transform(train_image, train_label)\nprint('tensor shape:', train_image2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Images in tensor are distorted because they no longer sit in (0, 255) range.\nLet's convert them back so we can see them clearly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_image2 = train_image2.transpose(\n    (1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\ntrain_image2 = (train_image2 * 255).clip(0, 255)\nax = viz.plot_bbox(train_image2.asnumpy(), train_label2[:, :4],\n                   labels=train_label2[:, 4:5],\n                   class_names=train_dataset.classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "apply transforms to validation image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "val_image2, val_label2 = val_transform(val_image, val_label)\nval_image2 = val_image2.transpose(\n    (1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\nval_image2 = (val_image2 * 255).clip(0, 255)\nax = viz.plot_bbox(val_image2.clip(0, 255).asnumpy(), val_label2[:, :4],\n                   labels=val_label2[:, 4:5],\n                   class_names=train_dataset.classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transforms used in training include random expanding, random cropping, color distortion, random flipping, etc.\nIn comparison, validation transforms are simpler and only resizing and\ncolor normalization is used.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Loader\n------------------\nWe will iterate through the entire dataset many times during training.\nKeep in mind that raw images have to be transformed to tensors\n(mxnet uses BCHW format) before they are fed into neural networks.\nIn addition, to be able to run in mini-batches,\nimages must be resized to the same shape.\n\nA handy DataLoader would be very convenient for us to apply different transforms and aggregate data into mini-batches.\n\nBecause the number of objects varies a lot across images, we also have\nvarying label sizes. As a result, we need to pad those labels to the same size.\nTo deal with this problem, GluonCV provides :py:class:`gluoncv.data.batchify.Pad`,\nwhich handles padding automatically.\n:py:class:`gluoncv.data.batchify.Stack` in addition, is used to stack NDArrays with consistent shapes.\n:py:class:`gluoncv.data.batchify.Tuple` is used to handle different behaviors across multiple outputs from transform functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv.data.batchify import Tuple, Stack, Pad\nfrom mxnet.gluon.data import DataLoader\n\nbatch_size = 2  # for tutorial, we use smaller batch-size\n# you can make it larger(if your CPU has more cores) to accelerate data loading\nnum_workers = 0\n\n# behavior of batchify_fn: stack images, and pad labels\nbatchify_fn = Tuple(Stack(), Pad(pad_val=-1))\ntrain_loader = DataLoader(\n    train_dataset.transform(train_transform),\n    batch_size,\n    shuffle=True,\n    batchify_fn=batchify_fn,\n    last_batch='rollover',\n    num_workers=num_workers)\nval_loader = DataLoader(\n    val_dataset.transform(val_transform),\n    batch_size,\n    shuffle=False,\n    batchify_fn=batchify_fn,\n    last_batch='keep',\n    num_workers=num_workers)\n\nfor ib, batch in enumerate(train_loader):\n    if ib > 3:\n        break\n    print('data:', batch[0].shape, 'label:', batch[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SSD Network\n------------------\nGluonCV's SSD implementation is a composite Gluon HybridBlock\n(which means it can be exported\nto symbol to run in C++, Scala and other language bindings.\nWe will cover this usage in future tutorials).\nIn terms of structure, SSD networks are composed of base feature extraction\nnetwork, anchor generators, class predictors and bounding box offset predictors.\n\nFor more details on how SSD detector works, please refer to our introductory\n[tutorial](http://gluon.mxnet.io/chapter08_computer-vision/object-detection.html)\nYou can also refer to the original paper to learn more about the intuitions\nbehind SSD.\n\n`Gluon Model Zoo <../../model_zoo/index.html>`__ has a lot of built-in SSD networks.\nYou can load your favorite one with one simple line of code:\n\n.. hint::\n\n   To avoid downloading models in this tutorial, we set `pretrained_base=False`,\n   in practice we usually want to load pre-trained imagenet models by setting\n   `pretrained_base=True`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv import model_zoo\nnet = model_zoo.get_model('ssd_300_vgg16_atrous_voc', pretrained_base=False)\nprint(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SSD network is a HybridBlock as mentioned before. You can call it with\nan input as:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mxnet as mx\nx = mx.nd.zeros(shape=(1, 3, 512, 512))\nnet.initialize()\ncids, scores, bboxes = net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SSD returns three values, where ``cids`` are the class labels,\n``scores`` are confidence scores of each prediction,\nand ``bboxes`` are absolute coordinates of corresponding bounding boxes.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SSD network behave differently during training mode:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mxnet import autograd\nwith autograd.train_mode():\n    cls_preds, box_preds, anchors = net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In training mode, SSD returns three intermediate values,\nwhere ``cls_preds`` are the class predictions prior to softmax,\n``box_preds`` are bounding box offsets with one-to-one correspondence to anchors\nand ``anchors`` are absolute coordinates of corresponding anchors boxes, which are\nfixed since training images use inputs of same dimensions.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training targets\n------------------\nUnlike a single ``SoftmaxCrossEntropyLoss`` used in image classification,\nthe loss used in SSD is more complicated.\nDon't worry though, because we have these modules available out of the box.\n\nTo speed up training, we let CPU to pre-compute some training targets.\nThis is especially nice when your CPU is powerful and you can use ``-j num_workers``\nto utilize multi-core CPU.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we provide anchors to the training transform, it will compute\ntraining targets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mxnet import gluon\ntrain_transform = presets.ssd.SSDDefaultTrainTransform(width, height, anchors)\nbatchify_fn = Tuple(Stack(), Stack(), Stack())\ntrain_loader = DataLoader(\n    train_dataset.transform(train_transform),\n    batch_size,\n    shuffle=True,\n    batchify_fn=batchify_fn,\n    last_batch='rollover',\n    num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loss, Trainer and Training pipeline\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv.loss import SSDMultiBoxLoss\nmbox_loss = SSDMultiBoxLoss()\ntrainer = gluon.Trainer(\n    net.collect_params(), 'sgd',\n    {'learning_rate': 0.001, 'wd': 0.0005, 'momentum': 0.9})\n\nfor ib, batch in enumerate(train_loader):\n    if ib > 0:\n        break\n    print('data:', batch[0].shape)\n    print('class targets:', batch[1].shape)\n    print('box targets:', batch[2].shape)\n    with autograd.record():\n        cls_pred, box_pred, anchors = net(batch[0])\n        sum_loss, cls_loss, box_loss = mbox_loss(\n            cls_pred, box_pred, batch[1], batch[2])\n        # some standard gluon training steps:\n        # autograd.backward(sum_loss)\n        # trainer.step(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This time we can see the data loader is actually returning the training targets for us.\nThen it is very naturally a gluon training loop with Trainer and let it update the weights.\n\n.. hint::\n\nPlease checkout the full :download:`training script\n<../../../scripts/detection/ssd/train_ssd.py>` for complete\nimplementation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n\n.. [Liu16] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg. SSD: Single Shot MultiBox Detector. ECCV 2016.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}